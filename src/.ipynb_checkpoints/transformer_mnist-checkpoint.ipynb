{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer with MNIST (or Fashion MNIST)\n",
    "\n",
    "* `Attention is All You Need`, [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)\n",
    "  * Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
    "  \n",
    "* This code is available to tensorflow version 2.0\n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers) [`tf.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses)\n",
    "  \n",
    "![title](pics/transformer_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'transformer_mnist'\n",
    "train_dir = os.path.join('train', model_name, 'exp')\n",
    "dataset_name = 'mnist'\n",
    "assert dataset_name in ['mnist', 'fashion_mnist']\n",
    "\n",
    "max_epochs = 50\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "width, height = 14, 14\n",
    "TEST = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 14, 14)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/QAAAEICAYAAADx6r8pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df7RcZX3v8c8nQcpPDZoDjSEYrClX6mqVFcDqWpVeUMAfDS71Fm75UaE3alQoC1uxXIVr1cu6VUHFaqPBhFsK5aao4KICxbJYvUuEBFiQAAbk55FIEoGAP64Y8r1/zD7bIeScM2fvPbPneeb9WmvWOTNnnnn2yUremWfPnj2OCAEAAAAAgLTMansDAAAAAADAzLGgBwAAAAAgQSzoAQAAAABIEAt6AAAAAAASxIIeAAAAAIAEsaAHAAAAACBBLOgzZvurtj9ecey/2j6l6W0CgFFChwGgfbQYOTOfQz+cbD8k6S8i4t/a3hYAGEV0GADaR4uBqfEKfaJs79L2NgDAKKPDANA+WoxRx4J+CNn+35IOkHS17Z/Z/mvbC22H7dNsPyLpe8V9/4/tn9jeavsm27/X9TgrbX+q+P4I2+O2z7K9yfZG2++dYhtutP0Xxfd/bvv/2r7A9lO2H7D9huL2R4vHO6Vr7Nts32776eLn5+3w2Cfbftj2T21/3PZDto8qfjbL9tm2f1T8/ArbL23uTxcApkeH6TCA9tFiWozpsaAfQhFxkqRHJL0jIvaKiP/V9eM3SXq1pKOL6/8qaZGkfSXdJunSKR76tyW9RNJ8SadJ+rLtfXrcrMMl3SnpZZL+SdLlkg6V9CpJJ0q6yPZexX1/LulkSXMkvU3SB2wfJ0m2D5b095L+TNK8ru2ZcLqk44rf8+WSnpT05R63EQAaQYfpMID20WJajOmxoE/PeRHx84j4pSRFxMUR8UxE/ErSeZL+wPZLJhn7a0mfjIhfR8Q1kn4m6aAe530wIr4REc9J+mdJC4rH+lVEXCfpWXVCpoi4MSLuiojtEXGnpMvUiZEkvVvS1RHxHxHxrKRPSOo+kcP7JJ0TEeNdv9O7zeFUAIYHHQaA9tFiQCzoU/ToxDe2Z9s+vzgU52lJDxU/mjvJ2J9GxLau67+QtNck993R413fT4Rzx9v2KrbrcNv/bnuz7a2S3t+1TS/v/h0i4heSftr1OK+Q9M3iMKanJN0j6TlJ+/W4nQDQb3QYANpHiwGxoB9mk338QPft/1XSEklHqXOYzsLidvdvs3ryT5KukrQgIl4i6av6zTZtlLT/xB1t767OIUsTHpV0bETM6brsFhE/HtC2A8AEOkyHAbSPFtNiTIEF/fB6XNIrp7nP3pJ+pc7evD0kfabfG9WjvSU9ERH/z/Zh6kR2wmpJ7yhOILKrpP+h58f2q5I+bfsVkmR7zPaSQW04AHShw6LDAFpHi0WLMTkW9MPrf0r678VhNh+Z5D6XSHpY0o8l3S3p5kFt3DSWSfqk7WfUeT/QFRM/iIj1kj6szglENkp6RtImdSIsSV9QZ0/mdcX4m9U5+QgADBodpsMA2keLaTGm4IjJjmIB+q84C+hTkhZFxINtbw8AjBo6DADto8WoilfoMXC232F7D9t7SvqspLv0m5OXAAD6jA4DQPtoMZrAgh5tWCLpseKySNLxwaEiADBIdBgA2keLURuH3AMAAAAAkCBeoQcAAAAAIEG7DHKyuXPnxsKFCwc5JTBSHnroIW3ZsqXSZ67ansnhOtdGxDFTPNYCdc44+9uStktaHhFfsH2epP8maXNx17+JiGuKMR+TdJqk5ySdHhHXzvy3wHToMNB/a9eu3RIRY1XGNtViOjzcaDHQX8PynHgQBrqgX7hwodasWTPIKYGRsnjx4kFNNXean2+TdFZE3GZ7b0lrbV9f/OyCiPhs951tHyzpeEm/J+nlkv7N9u9GxHNNb/ioo8NA/9l+eEBTTdViOjzEaDHQX0P0nLjvBrqgBzDc7N52ZE537o2I2KjOZ6oqIp6xfY+k+VMMWSLp8oj4laQHbd8v6TBJ3+9pgwAgI020mA4DQHVNPSceBN5DD6A0a9asni6S5tpe03VZOtlj2l4o6XWSflDc9CHbd9q+2PY+xW3zJT3aNWxcUz/xBIBsNd1iOgwAMzODDreOV+gBlHrdGylpS0RMeyyT7b0k/Yukv4yIp21/RdLfSori6+cknSppZxO3v8sTAFrQZIvpMADM3Aw63LpauxVsH2P7h7bvt312UxsFYPBs93zp8fFepM6TyEsj4kpJiojHI+K5iNgu6WvqHM4pdV4JWtA1fH91PpMVPaDFQD6abDEdHhw6DOSj6efE/VZ5QW97tqQvSzpW0sGSTihOqAIgUQ0+ibSkFZLuiYjPd90+r+tu75S0rvj+KknH2/4t2wdKWiTplsZ+sYzRYiA/TbSYDg8OHQbyk9KCvs4h94dJuj8iHpAk25erc0KVu5vYMACD12CY3ijpJEl32b6juO1v1HmS81p1DuN8SNL7JCki1tu+Qp1+bJP0Qc6s3DNaDGSmoRbT4cGhw0BmhmWx3os6C/qdnTzl8B3vVJygZakkHXDAATWmA9BvTcUrIv5DO38/5jVTjPm0pE83sgGjZdoW02EgLU20mA4PFM+JgcyktKCv8x76nk6eEhHLI2JxRCweGxurMR2AfrKd1Bk9UZq2xXQYSActThLPiYGMpNbhOq/Qc/IUIDMp7Y1EiRYDmaHFyaHDQGZS6nCd3Qq3Slpk+0Dbu0o6Xp0TqgBIVEonAEGJFgOZocXJocNAZlLqcOVX6CNim+0PSbpW0mxJF0fE+sa2DMDADUuY0DtaDOSHFqeFDgP5SanDdQ65V0RcoylOrgIgLSnFC79Bi4G80OL00GEgLyl1uNaCHkA+Jk4AAgBoDy0GgHal1mEW9ABKKe2NBIBc0WIAaFdKHWZBD6CUUrwAIFe0GADalVKHWdADKKUULwDIFS0GgHal1GEW9AAkaag+fgMARhUtBoB2pdZhFvQASinFCwByRYsBoF0pdZgFPYBSSmf0BIBc0WIAaFdKHWZBD6CU0t5IAMgVLQaAdqXUYRb0ACSl934hAMgRLQaAdqXWYRb0AEopxQsAckWLAaBdKXWYBT2AUkrxAoBc0WIAaFdKHWZBD6CU0glAACBXtBgA2pVSh1nQA5CU3vuFACBHtBgA2pVah1nQAyilFC8AyBUtBoB2pdRhFvQASinFCwByRYsBoF0pdZgFPYBSSvECgFzRYgBoV0odZkEPoJRSvAAgV7QYANqVUodZ0Gfu17/+da3x27ZtqzX+5ptvrjz2JS95SWtz77XXXrXmPvnkk2uNb4PtpM7oCYyK1atX1xr/4Q9/uPLYww8/vNbc3/rWt2qNH0W0GEDTrr766spjjzrqqFpz77777rXGtyG1DrOgB1BKaW8kAOSKFgNAu1LqMAt6AKWU4gUAuaLFANCulDrMgh5AKaV4AUCuaDEAtCulDrOgByCpE66U4gUAOaLFANCu1Dpc+d3+thfY/nfb99heb/uMJjcMwOBNBGy6C4YHLQbyQ4vTQoeB/DTV4cn6YPultq+3fV/xdZ/idtv+ou37bd9p+5Dp5qjzCv02SWdFxG2295a01vb1EXF3jccE0KKUzuiJEi0GMkOLk0OHgcw02OGd9kHSn0u6ISLOt322pLMlfVTSsZIWFZfDJX2l+Dr5tlbdsojYGBG3Fd8/I+keSfOrPh6A9vGqUHpoMZAfWpwWOgzkp6kOT9GHJZJWFXdbJem44vslki6JjpslzbE9b6o5Gtn1YHuhpNdJ+sFOfrbU9hrbazZv3tzEdAD6oNdw8SRyeE3WYjoMpIMWp43nxED6+tXhHfqwX0RslDqLfkn7FnebL+nRrmHjmmYHYe0Fve29JP2LpL+MiKd3/HlELI+IxRGxeGxsrO50APqIJ5HpmqrFdBhICy1OE8+JgXzMoMNzJ3bUFZelkzzelH3ovutObouptrXWWe5tv6jYsEsj4so6jwWgfTxBTBMtBvJCi9NDh4G8zKDDWyJi8TSPtbM+PG57XkRsLA6p31TcPi5pQdfw/SU9NtXj1znLvSWtkHRPRHy+6uMAGB6zZs3q6YLhQYuB/NDitNBhID9NdXiKPlwl6ZTi+1Mkfbvr9pPd8XpJWycOzZ90W2f6y3V5o6STJP1n23cUl7fWeDwALWry/UIewEd0oESLgYw01WI6PFB0GMhIk8+JNXkfzpf0Ztv3SXpzcV2SrpH0gKT7JX1N0rLpJqh8yH1E/Id2fow/gEQ1eJhn3z+iAx20GMhPQy2mwwNCh4H8NPWceJo+HLmT+4ekD85kDo7XAlBqam/kID6iAwBy1USL6TAAVNfgK/R9V+ukeADyMoMwzbW9puv68ohYPsljLtQkH9Fhe7qP6JjyPUMAkKOmW0yHAWBmhmWx3gsW9D362c9+VnnsueeeW2vu22+/vfLYdevW1Zq7zc9JPeOMM2qN37p1a+Wx73nPe2rNnaoZxGvaM3oWj/e8j+iY4vFn/BEdwCBt37698tgrr6x3wusTTzyx1vjdd9+98tiHH3641txf/OIXK489/fTTa82dsiZbTIexowsuuKDW+DPPPLOhLcGgfOMb36g89g1veEOtuev8H9QmFvQAkmO70bMmu88f0QEAOWqyxXQYAGau6efE/ZbOlgLou6beL2T3/yM6ACBXTbSYDgNAdbyHHkCSGgzTxEd03GX7juK2v1HnIzmusH2apEckTby34RpJb1XnIzp+Iem9TW0IAKSmoRbTYQCoaFgW671gQQ+glNJHdABArppoMR0GgOpY0ANIzjAdOgQAo4oWA0C7UuswC3oApZTiBQC5osUA0K6UOsyCHkAppTN6AkCuaDEAtCulDrOgB1BKaW8kAOSKFgNAu1LqMAt6AJLSe78QAOSIFgNAu1LrMAt6AKWU4gUAuaLFANCulDrMgh5AKaV4AUCuaDEAtCulDrOgB1BK6QQgAJArWgwA7UqpwyzoAUhK7/1CAJAjWgwA7UqtwyzoAZRSihcA5IoWA0C7UuowC/oe7bbbbpXHbtiwodbc4+Pjlcf+8pe/rDX3ihUrao3/zne+U3nshRdeWGtuzFxK8QIGqU6PzjrrrFpzH3LIIbXGr1+/vvLY97///bXm/tKXvlR57Omnn15r7pTRYvTT5ZdfXmv8mWee2dCWoFe33HJLrfEPPvhg5bEve9nLas2dqpQ6zIIeQCmleAFArmgxALQrpQ6zoAdQSileAJArWgwA7UqpwyzoAUjqhCulM3oCQI5oMQC0K7UOs6AHUEppbyQA5IoWA0C7Uupw7V0Ptmfbvt129bOfARgKEx/TMd0Fw4cWA/mgxWmiw0A+UupwE6/QnyHpHkkvbuCxALRoWMKESmgxkAlanCw6DGQipQ7XeoXe9v6S3ibp681sDoC29LonMqXAjQpaDOSDFqeJDgP5SK3DdQ+5v1DSX0vaPtkdbC+1vcb2ms2bN9ecDkA/pRQvPM+ULabDQFpocZJ4TgxkJKUOV17Q2367pE0RsXaq+0XE8ohYHBGLx8bGqk4HYABmzZrV0wXDo5cW02EgLbQ4LTwnBvKTUofrvIf+jZL+xPZbJe0m6cW2/zEiTmxm0wAM0jDtacSM0GIgI7Q4SXQYyEhqHa68WyEiPhYR+0fEQknHS/oe4QLSltLhReigxUB+aHFa6DCQn5Q6zOfQAygNS5gAYJTRYgBoV0odbmRBHxE3SrqxiccC0J6U4oUXosVAHmhxuugwkIeUOswr9AAkdcI1LCf3AIBRRYsBoF2pdZgFPYBSSnsjASBXtBgA2pVSh1nQ92iXXar/UX3rW9+qNfd1111XeewnP/nJWnOfeuqprY7HYKUUL2AmbrrpplrjzznnnMpjjz322Fpzr1q1qtb4p59+uvLY3/md36k197JlyyqPvfXWW2vNfeihh9Ya3yZajOmsW7eu8titW7c2uCUYhBtvvLHW+MWLFzezISMkpQ6zoAdQSileAJArWgwA7UqpwyzoAZRSihcA5IoWA0C7UupwOu/2B9BXvX7eZkqBA4DU0GIAaFeTHbZ9se1Nttd13Xae7R/bvqO4vLXrZx+zfb/tH9o+upft5RV6AKWUzugJALmixQDQrgY7vFLSRZIu2eH2CyLis9032D5Y0vGSfk/SyyX9m+3fjYjnppqABT2AEq/4AED7aDEAtKupDkfETbYX9nj3JZIuj4hfSXrQ9v2SDpP0/akGsQsYQInDPAGgfbQYANo1gw7Ptb2m67K0xyk+ZPvO4pD8fYrb5kt6tOs+48VtU+IVegCSxBNEABgCtBgA2jXDDm+JiJl+LuBXJP2tpCi+fk7SqZJ2NmlM92C8Qg+glNIJQAAgV7QYANrVzyOlIuLxiHguIrZL+po6h9VLnVfkF3TddX9Jj033eCzoAZRmzZrV06UHKyUds5PbL4iI1xaXa6QXnADkGEl/b3t2Q78SACSHFgNAuxrs8AvYntd19Z2SJna6XiXpeNu/ZftASYsk3TLd43HIPYBSSicAAYBc0WIAaFdTHbZ9maQj1Hmv/bikcyUdYfu16hxO/5Ck90lSRKy3fYWkuyVtk/TB6c5wL7GgB1CY4aFDc22v6bq+PCKW9zDuQ7ZPlrRG0lkR8aQ6J/u4ues+PZ0ABAByRIsBoF1NnsskIk7Yyc0rprj/pyV9eiZzsKAHUErpBCAAkCtaDADtSunkpCzoAZT6Ga+IeLxrnq9J+k5xtdIJQAAgV7QYANqV0oKek+IBKPXzjJ5NnwAEAHJFiwGgXf3scNN4hX4AZs+ud5LYo4+u/skxX/rSl2rN/fnPf77W+D/90z+tPHb+fN66N0i2K5+tcyeP1fcTgGD0PPXUU5XHvutd76o19z/8wz+0Nveee+5Za/zY2Fit8XVs37698ti77rqr1tyHHnporfFtocXoxYYNGyqPfeUrX9ngloyO556r98/he9/7XuWxn/nMZ2rNvWLFpG/Zxk402eFBYEEPoJTSCUAAIFe0GADaNSyvvveCBT2AUkrxAoBc0WIAaFdKHWZBD6CUUrwAIFe0GADalVKHWdADKKUULwDIFS0GgHal1OFa7/a3Pcf2atv32r7H9h82tWEABqvXs3mmFLhRQYuBfNDiNNFhIB+pdbjuK/RfkPTdiHi37V0l7dHANgFoSUpn9MTz0GIgI7Q4SXQYyEhKHa68oLf9Ykl/JOnPJSkinpX0bDObBaANw7KnEb2jxUB+aHFa6DCQn5Q6XGfXwyslbZb0Ddu32/667Rd8WK7tpbbX2F6zefPmGtMB6LeUDi9CadoW02EgLbQ4OTwnBjKTUofrLOh3kXSIpK9ExOsk/VzS2TveKSKWR8TiiFg8NjZWYzoA/ZTa+4VQmrbFdBhIBy1OEs+JgYyk1uE6C/pxSeMR8YPi+mp1YgYgUSnFCyVaDGSGFieHDgOZSanDld9DHxE/sf2o7YMi4oeSjpR0d3ObBmDQUjoBCDpoMZAfWpwWOgzkJ6UO1z3L/YclXVqczfMBSe+tv0kA2jIsexoxY7QYyAgtThIdBjKSUodrLegj4g5JixvaFgAtGqZDhzAztBjIBy1OEx0G8pFah+u+Qg8gIynFCwByRYsBoF0pdZgFPYBSSvECgFzRYgBoV0odZkGfgDonZbjkkktqzX3SSSfVGn/RRRdVHrt69epacx9yCCeYnamU4oXR87nPfa7y2IULF9aa++STT641HjO3554v+BjvkUGLMZ06zw1/9KMf1Zq7znO7n/zkJ7XmXr9+feWxTz75ZK25X/SiF9Uaf/TRR1ceu3Xr1lpzH3vssbXGj6KUOsyCHoCkTrhSOqMnAOSIFgNAu1LrMAt6AKWU9kYCQK5oMQC0K6UOs6AHUEopXgCQK1oMAO1KqcMs6AGUUooXAOSKFgNAu1LqMAt6AKWU4gUAuaLFANCulDrMgh6ApE64UooXAOSIFgNAu1LrMAt6AKWUzugJALmixQDQrpQ6zIIeQCmlvZEAkCtaDADtSqnDLOgBlFKKFwDkihYDQLtS6jALegCS0nu/EADkiBYDQLtS6zALegCllOIFALmixQDQrpQ6zIIeQCmlE4AAQK5oMQC0K6UOs6AHUEppbyQA5IoWA0C7UuowC3oAktJ7vxAA5IgWA0C7UuswC3oApZTiBQC5osUA0K6UOsyCPnNz586tNf7qq6+uNf7000+vPPaoo46qNfcDDzxQeeycOXNqzZ2qlOKF0bNhw4bKY9/1rnc1uCVpiYjKYz/+8Y/Xmvstb3lL5bHvfve7a82dMlqM6Rx33HGVx86ePbvW3Fu3bq08tu7zq5NOOqny2IMOOqjW3HVdd911lccuWLCg1tx77LFHrfGjKKUOp/NufwB9N3GI0XQXAED/0GIAaFdTHbZ9se1Nttd13fZS29fbvq/4uk9xu21/0fb9tu+0fUgv28qCHoCkTrhmzZrV0wUA0B+0GADa1XCHV0o6ZofbzpZ0Q0QsknRDcV2SjpW0qLgslfSVXibgfwMAJV4VAoD20WIAaFdTHY6ImyQ9scPNSyStKr5fJem4rtsviY6bJc2xPW+6OWot6G2faXu97XW2L7O9W53HA9CulA4vwm/QYiAvtDg9dBjIyww6PNf2mq7L0h4efr+I2ChJxdd9i9vnS3q0637jxW1Tqrygtz1f0umSFkfEayTNlnR81ccD0L4GXxVaqT4fXoQOWgzkhxanhQ4D+ZlBh7dExOKuy/I60+7ktmnPbFv3kPtdJO1uexdJe0h6rObjAWhRSocX4XloMZARWpwkOgxkpMEdqzvz+ERfi6+bitvHJXV/pMH+6qEllRf0EfFjSZ+V9IikjZK2RsQLPo/B9tKJQxA2b95cdToAfdZruIbl8CJ09NJiOgykgxanh+fEQF5m2OEqrpJ0SvH9KZK+3XX7ye54vTot2Tjdg9U55H4fdfbmHijp5ZL2tH3ijveLiOUThyCMjY1VnQ7AAMzgjJ6tH16Ejl5aTIeBtNDitPCcGMhPU2e5t32ZpO9LOsj2uO3TJJ0v6c2275P05uK6JF0j6QFJ90v6mqRlvWzrLjP/9UpHSXowIjYXG3ulpDdI+scajwmgRTX2NPbicdvzImJjE4cXoUSLgczQ4uTQYSAzTXU4Ik6Y5EdH7uS+IemDM52jznvoH5H0ett7uPMbHynpnhqPB6BlKR1ehBItBjJDi5NDh4HM9LnDjar8Cn1E/MD2akm3Sdom6XZJdQ71AtCiJsNUHF50hDrv7xyXdK46hxNdURxq9Iik9xR3v0bSW9U5vOgXkt7byEaMCFoM5IUWp4cOA3kZpsV6L+occq+IOFed/xwAZCClw4vwG7QYyAstTg8dBvIyMgt6AHnp5eQeAID+osUA0K6UOsyCHoCk9A4vAoAc0WIAaFdqHWZBn7k777yz1vjzzz9/+jtN4bvf/W7lsXvvvXetuefMmVNr/ChKKV4YPdu3b688dv78dD9Oe3x8vNb4Zct6+tSbnXrFK15Ra+5rr7221vhRRYvRT+94xzva3oSR9MQTT1Qee8QRRzS3IehJSh1mQQ+glFK8ACBXtBgA2pVSh1nQAyilFC8AyBUtBoB2pdRhFvQASinFCwByRYsBoF0pdZgFPQBJnXCldEZPAMgRLQaAdqXWYRb0AEop7Y0EgFzRYgBoV0odZkEPoJRSvAAgV7QYANqVUodZ0AMopRQvAMgVLQaAdqXUYRb0ACR1wpVSvAAgR7QYANqVWodZ0AMopXQCEADIFS0GgHal1GEW9ABKKe2NBIBc0WIAaFdKHWZBD6CUUrwAIFe0GADalVKHWdADkJTe+4UAIEe0GADalVqHWdADKKUULwDIFS0GgHal1GEW9ABKKcULAHJFiwGgXSl1mAU9gFJKZ/QEgFzRYgBoV0odZkE/AJs2bao1/hOf+ETlsatWrao196677lpr/LJlyyqP/chHPlJrbsxMau8Xwuip85/rOeecU2vuDRs2VB5700031Zr73nvvrTV+6dKllcf+1V/9Va25MXO0GMCOtmzZ0vYmjJTUOsyCHkAppXgBQK5oMQC0K6UOs6AHUEopXgCQK1oMAO1KqcMs6AGUUooXAOSKFgNAu1Lq8LRvSLR9se1Nttd13fZS29fbvq/4uk9/NxPAIEy8Z2i6CwaPFgOjgxYPJzoMjI6UOtzLGYZWSjpmh9vOlnRDRCySdENxHUDCbGvWrFk9XdCKlaLFQPZo8VBbKToMZC+1Dk+7FRFxk6Qndrh5iaSJ06evknRcw9sFoAUp7Y0cNbQYGB20eDjRYWB0pNThqu+h3y8iNkpSRGy0ve9kd7S9VNJSSTrggAMqTgdgEIYlTOhZTy2mw0BaaHFSeE4MZCilDvf9OIGIWB4RiyNi8djYWL+nA1BDSnsj0Ts6DKSFFueJFgPpSKnDVRf0j9ueJ0nF103NbRKANvQarmGJFyTRYiA7tDg5dBjITGodrrqgv0rSKcX3p0j6djObA6BNKZ0ABJJoMZAlWpwUOgxkKKUOT/seetuXSTpC0lzb45LOlXS+pCtsnybpEUnv6edGAhiMYdnTiBeixcDooMXDiQ4DoyOlDk+7oI+IEyb50ZENbwuAlqUUr1FDi4HRQYuHEx0GRkdKHa56lnsAmRmm9wIBwKiixQDQrtQ6zIIeQCmleAFArmgxALSryQ7bfkjSM5Kek7QtIhbbfqmkf5a0UNJDkv5LRDxZ5fFHZkF/88031xp/4YUXVh777W/XOz/Ks88+W3ns+973vlpzn3feebXG77vvpB/HiiHEk0gMs2XLllUee8stt9Sa+1Of+lTlsSecMNlRur1ZsWJFrfGvetWrao3H4NFiAN0eeeSRtjdh5PShw38cEVu6rp8t6YaION/22cX1j1Z54JFZ0AOYXpNn6+z33kgAyFVTLabDAFDNAM5gv0Sdk2xK0ipJN6rign44zrUPoHV9+szNP46I10bE4uL6xN7IRZJuKK4DAAp9aDEdBoAZmGGH59pe03VZupOHDEnX2V7b9fP9ImKjJBVfKx/WzCv0AEoDOMyzsb2RAJCrPreYDgPANGbQ4S1dO0wn88aIeMz2vpKut31vva17Pl6hB1BKaW8kAOSqwRbTYQCooHPbm/sAAAoXSURBVMkjpSLiseLrJknflHSYpMdtzyvmmidpU9Vt5RV6AKWU9kYCQK4abDEdBoAKmjpSyvaekmZFxDPF92+R9ElJV0k6RdL5xdfKZ1FnQQ+g1ORhnt17I20/b29kRGysuzcSAHLVVIvpMABU0+Bz4v0kfbN4vF0k/VNEfNf2rZKusH2apEckvafqBCzoAUjqhKvBMyv3fW8kAOSoqRbTYQCopsnnxBHxgKQ/2MntP5V0ZBNzsKAHUEppbyQA5KqhFtNhAKhoACeKbgwLegClBg/z7PveSADIVRMtpsMAUB0LegBJSileAJArWgwA7UqpwyzoAUjSjD5+AwDQH7QYANqVWodZ0AMoNXUCEABAdbQYANqVUodZ0AMopbQ3EgByRYsBoF0pdZgFPYBSSvECgFzRYgBoV0odZkEPQFJ67xcCgBzRYgBoV2odHpkF/d13311r/Ktf/erKY9/5znfWmvuQQw6pPHbRokW15sZoSSleGD1vetObKo998MEHG9wSoL9oMZCfOv+HPfnkkw1uCXqRUodHZkEPYHopxQsAckWLAaBdKXWYBT2AUkpn9ASAXNFiAGhXSh1mQQ9AUnrvFwKAHNFiAGhXah2edteD7Yttb7K9ruu2v7N9r+07bX/T9pz+biaAQZgI2HQXDB4tBkYHLR5OdBgYHSl1uJdjCVZKOmaH266X9JqI+H1JGyR9rOHtAtCClOI1glaKFgMjgRYPrZWiw8BISKnD0y7oI+ImSU/scNt1EbGtuHqzpP37sG0ABiyleI0aWgyMDlo8nOgwMDpS6nAT76E/VdI/N/A4AFo2LGFCJbQYyAQtThYdBjKRUodrLehtnyNpm6RLp7jPUklLJemAAw6oMx2APrKd1Bk98RvTtZgOA+mgxWniOTGQj9Q6XHlLbZ8i6e2S/iwiYrL7RcTyiFgcEYvHxsaqTgdgAFI6vAgdvbSYDgNpocVp4TkxkJ+UOlzpFXrbx0j6qKQ3RcQvmt0kAG0ZljChN7QYyBMtTgcdBvKUUod7+di6yyR9X9JBtsdtnybpIkl7S7re9h22v9rn7QQwACntjRw1tBgYHbR4ONFhYHSk1OFpX6GPiBN2cvOKPmwLgBYNU5jwQrQYGA20eHjRYWA0pNbhJs5yDyATKZ0ABAByRYsBoF0pdZgFPYBSSnsjASBXtBgA2pVSh0dmQX/qqae2vQnA0EspXgCQK1oM5GfevHmVx37gAx9ocEvQi5Q6PDILegBTS+39QgCQI1oMAO1KrcMs6AGUUooXAOSKFgNAu1LqMAt6AKWU4gUAuaLFANCulDrMgh6ApE64UjqjJwDkiBYDQLtS6zALegCllPZGAkCuaDEAtCulDrOgB1BKKV4AkCtaDADtSqnDLOgBlFKKFwDkihYDQLtS6jALegCllOIFALmixQDQrpQ6zIIegKT0PnMTAHJEiwGgXal1mAU9gFJKZ/QEgFzRYgBoV0odZkEPoJTS3kgAyBUtBoB2pdRhFvQASinFCwByRYsBoF0pdTidYwkA9NXE+4V6ufT4eMfY/qHt+22f3efNB4AsNNliOgwAM5fac2IW9ABKDT6JnC3py5KOlXSwpBNsH9znzQeALDTRYjoMANWl9JyYQ+4BlBo8Achhku6PiAckyfblkpZIurupCQAgVw21mA4DQEUpPSce6IJ+7dq1W2w/PMVd5kraMqjtYW7mznDuV1QduHbt2mttz+3x7rvZXtN1fXlELO+6Pl/So13XxyUdXnXb0Bw6zNxDNHfb8+feYjo8xGgxczN33+cehg5LA2jxQBf0ETE21c9tr4mIxYPaHuZm7lGbeyoRcUyDD7ezY5CiwcdHRXSYuYdl7rbnb/t3n0yDLabDQ4wWMzdzj0SHpQG0mPfQA+iHcUkLuq7vL+mxlrYFAEYRHQaA9vW9xSzoAfTDrZIW2T7Q9q6Sjpd0VcvbBACjhA4DQPv63uJhOyne8unvwtzMzdzDLiK22f6QpGslzZZ0cUSsb3mz0JtR/bfB3KM3f9u/e1/R4eSN6r8N5mburAyixY7g7VQAAAAAAKSGQ+4BAAAAAEgQC3oAAAAAABI0FAt628fY/qHt+22fPcB5F9j+d9v32F5v+4xBzd21DbNt3277OwOed47t1bbvLX7/Pxzg3GcWf97rbF9me7c+z3ex7U2213Xd9lLb19u+r/i6zwDn/rviz/1O29+0PacfcwMzRYtpcR/nosNAD+gwHe7zfLQ4Q60v6G3PlvRlScdKOljSCbYPHtD02ySdFRGvlvR6SR8c4NwTzpB0z4DnlKQvSPpuRPwnSX8wqG2wPV/S6ZIWR8Rr1Dk5xPF9nnalpB0/T/JsSTdExCJJNxTXBzX39ZJeExG/L2mDpI/1aW6gZ7SYFqu/LV4pOgxMiQ7TYfGcmBZX0PqCXtJhku6PiAci4llJl0taMoiJI2JjRNxWfP+MOv+A5w9ibkmyvb+kt0n6+qDmLOZ9saQ/krRCkiLi2Yh4aoCbsIuk3W3vImkP9flzcSPiJklP7HDzEkmriu9XSTpuUHNHxHURsa24erM6n0cJtI0W0+K+tZgOAz2hw3SY58SYsWFY0M+X9GjX9XENMCATbC+U9DpJPxjgtBdK+mtJ2wc4pyS9UtJmSd8oDm36uu09BzFxRPxY0mclPSJpo6StEXHdIObewX4RsbHYpo2S9m1hGyTpVEn/2tLcQDdaTIsH3WI6DDwfHabDPCfGjA3Dgt47uW2gn6Vney9J/yLpLyPi6QHN+XZJmyJi7SDm28Eukg6R9JWIeJ2kn6t/h9c8T/G+nCWSDpT0ckl72j5xEHMPG9vnqHOI26VtbwsgWkyLR7DFdBhDhg4PHh0eArS4nmFY0I9LWtB1fX/1+XCTbrZfpE64Lo2IKwc1r6Q3SvoT2w+pc0jVf7b9jwOae1zSeERM7HldrU7MBuEoSQ9GxOaI+LWkKyW9YUBzd3vc9jxJKr5uGuTktk+R9HZJfxYRA/3PGpgELabFg24xHQaejw7TYZ4TY8aGYUF/q6RFtg+0vas6J4O4ahAT27Y675m5JyI+P4g5J0TExyJi/4hYqM7v/L2IGMheuYj4iaRHbR9U3HSkpLsHMbc6hxW93vYexZ//kWrnBChXSTql+P4USd8e1MS2j5H0UUl/EhG/GNS8wDRoMS0edIvpMPB8dJgO85wYM9b6gr44EcKHJF2rzl/iKyJi/YCmf6Okk9TZE3hHcXnrgOZu24clXWr7TkmvlfSZQUxa7AFdLek2SXep83dweT/ntH2ZpO9LOsj2uO3TJJ0v6c2275P05uL6oOa+SNLekq4v/s59tR9zAzNBi1szEi2mw8D06HBrRqLDEi3OlTmyAQAAAACA9LT+Cj0AAAAAAJg5FvQAAAAAACSIBT0AAAAAAAliQQ8AAAAAQIJY0AMAAAAAkCAW9AAAAAAAJIgFPQAAAAAACfr/J+uDKpCAFEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "if dataset_name == 'mnist':\n",
    "  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.mnist.load_data()\n",
    "else:\n",
    "  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "train_images = tf.image.resize(train_images, size=[width, height])\n",
    "train_images = tf.cast(train_images[:, :, :, 0], tf.int64)\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "plt.figure(figsize=[18, 4])\n",
    "for i in range(3):\n",
    "    \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title('train image')\n",
    "    plt.imshow(train_images[i], cmap='binary')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (None, 14, 14), types: tf.int64>\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(117)\n",
    "# for train\n",
    "N = len(train_images)\n",
    "        \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transformer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reference : \n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention\n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/functional.html\n",
    "# https://github.com/openai/gpt-2/blob/master/src/model.py\n",
    "\n",
    "class MultiheadAttention(tf.keras.Model):\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.0):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        self.q_proj = layers.Dense(embed_dim)\n",
    "        self.k_proj = layers.Dense(embed_dim)\n",
    "        self.v_proj = layers.Dense(embed_dim)\n",
    "        \n",
    "        self.out_proj = layers.Dense(embed_dim)\n",
    "        \n",
    "    def call(self, query, key, value, attn_mask=None):\n",
    "        \n",
    "        # query : [batch, tgt_len, embed_dim]\n",
    "        # key   : [batch, src_len, embed_dim]\n",
    "        # value : [batch, src_len, embed_dim]\n",
    "        \n",
    "        batch, tgt_len, _ = query.shape\n",
    "        _, src_len, _ = key.shape\n",
    "        \n",
    "        '''\n",
    "        Query, Key, Value Projection\n",
    "        '''\n",
    "        # [batch, tgt_len, embed_dim]\n",
    "        q = self.q_proj(query)\n",
    "        # [batch, tgt_len, embed_dim]\n",
    "        k = self.k_proj(key)\n",
    "        # [batch, tgt_len, embed_dim]\n",
    "        v = self.v_proj(value)\n",
    "        \n",
    "        '''\n",
    "        Reshape for Multi-Head Attention\n",
    "        '''\n",
    "        # [batch, tgt_len, num_heads, head_dim]\n",
    "        q = tf.reshape(q, [batch, tgt_len, self.num_heads, self.head_dim])\n",
    "        # [batch, num_heads, tgt_len, head_dim]\n",
    "        q = tf.transpose(q, [0, 2, 1, 3])\n",
    "        \n",
    "        # [batch, src_len, num_heads, head_dim]\n",
    "        k = tf.reshape(k, [batch, src_len, self.num_heads, self.head_dim])\n",
    "        # [batch, num_heads, src_len, head_dim]\n",
    "        k = tf.transpose(k, [0, 2, 1, 3])\n",
    "        \n",
    "        # [batch, src_len, num_heads, head_dim]\n",
    "        v = tf.reshape(v, [batch, src_len, self.num_heads, self.head_dim])\n",
    "        # [batch, num_heads, src_len, head_dim]\n",
    "        v = tf.transpose(v, [0, 2, 1, 3])\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        w : Attention Output Weights\n",
    "        '''\n",
    "        # [batch, num_heads, tgt_len, src_len]\n",
    "        w = tf.matmul(q, k, transpose_b=True)\n",
    "        # scaling by square-root of head_dim\n",
    "        w = w / np.sqrt(self.head_dim)\n",
    "        \n",
    "        if attn_mask is not None:\n",
    "            w = w + attn_mask * -1e9\n",
    "            \n",
    "        # [batch, num_heads, tgt_len, src_len] \n",
    "        w = tf.nn.softmax(w, axis=-1)\n",
    "        \n",
    "        '''\n",
    "        a : Attention Output\n",
    "        '''\n",
    "        # [batch, num_heads, tgt_len, head_dim]\n",
    "        a = tf.matmul(w, v)\n",
    "        # [batch, tgt_len, num_heads, head_dim]\n",
    "        a = tf.transpose(a, [0, 2, 1, 3])\n",
    "        # [batch, tgt_len, embed_dim]\n",
    "        a = tf.reshape(a, [batch, tgt_len, self.embed_dim])\n",
    "        \n",
    "        out = self.out_proj(a)\n",
    "        \n",
    "        return out, tf.reduce_mean(w, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(tf.keras.Model):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout, activation=tf.nn.relu):\n",
    "        super(Feedforward, self).__init__()\n",
    "        \n",
    "        self.linear1 = layers.Dense(dim_feedforward, activation=activation)\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.linear2 = layers.Dense(d_model)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x, training=True)\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Reference :     \n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer\n",
    "class TransformerEncoderLayer(tf.keras.Model):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=tf.nn.relu):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout)\n",
    "        self.feed_forward = Feedforward(d_model, dim_feedforward, dropout, activation)\n",
    "        \n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def call(self, src, src_mask=None):\n",
    "        # src : [batch, length, d_model]\n",
    "        \n",
    "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask)\n",
    "        src = src + self.dropout1(src2, training=True)\n",
    "        src = self.norm1(src)\n",
    "        \n",
    "        src2 = self.feed_forward(src)\n",
    "        src = src + self.dropout2(src2, training=True)\n",
    "        src = self.norm2(src)\n",
    "        \n",
    "        return src\n",
    "    \n",
    "# Reference : \n",
    "# https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoder\n",
    "class TransformerEncoder(tf.keras.Model):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout, activation, num_layers):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder_layers = [TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation) \\\n",
    "                       for _ in range(num_layers)]\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def call(self, src, mask=None):\n",
    "        # src : [batch, src_len, embed_dim]\n",
    "        \n",
    "        output = src\n",
    "        for i in range(self.num_layers):\n",
    "            output = self.encoder_layers[i](output, src_mask=mask)\n",
    "            \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, d_model=512, vocab_size=256):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.transformer_encoder = TransformerEncoder(d_model=d_model, nhead=8, dim_feedforward=2048, dropout=0.1,\n",
    "                                                     activation=tf.nn.relu, num_layers=6)\n",
    "        self.logit_layer = layers.Dense(vocab_size)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_angles(pos, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    @staticmethod\n",
    "    def _positional_encoding(position, d_model):\n",
    "        angle_rads = Model._get_angles(np.arange(position)[:, np.newaxis],\n",
    "                               np.arange(d_model)[np.newaxis, :],\n",
    "                               d_model)\n",
    "\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_look_ahead_mask(size):\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "        return mask  # (seq_len, seq_len)\n",
    "\n",
    "    def call(self, images):\n",
    "        # images : [batch, src_length]\n",
    "        \n",
    "        _, src_length = images.shape\n",
    "        \n",
    "        # [batch, src_length, d_model]\n",
    "        src = self.embedding(images) + self._positional_encoding(src_length, self.d_model)\n",
    "        \n",
    "        mask = self._create_look_ahead_mask(src_length)\n",
    "        output = self.transformer_encoder(src, mask=mask)\n",
    "        logit = self.logit_layer(output)\n",
    "        \n",
    "        return logit\n",
    "    \n",
    "    def inference(self, images):\n",
    "        from tqdm.notebook import tqdm\n",
    "\n",
    "        for i in tqdm(range(0, width*height)):\n",
    "            logit = self.call(images)\n",
    "            sample = tf.random.categorical(logit[:, i], num_samples=1)\n",
    "            images = tf.concat([images[:, :i+1], sample, images[:, i+2:]], axis=1)\n",
    "        \n",
    "        return images[:, 1:]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Model object at 0x7f405b609a50>\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D-image to 1D-vector, 1D-vector to 2D-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vector(images):\n",
    "    batch, height, width = images.shape\n",
    "    vector = tf.reshape(images, [batch, height*width])\n",
    "    return vector\n",
    "\n",
    "def vector_to_image(vectors, height, width):\n",
    "    batch, dim = vectors.shape\n",
    "    images = tf.reshape(vectors, [batch, height, width])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a unconditional image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fe593536874a4c8077175c04d5acc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f40549f3350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = model.inference(tf.zeros([1, width*height], dtype=tf.int64))\n",
    "pred = vector_to_image(images, width, height)\n",
    "plt.imshow(pred[0], cmap='binary')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Define a single train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, optimizer, images):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "           \n",
    "        images_shifted = tf.concat([tf.zeros([images.shape[0], 1], dtype=tf.int64), images[:, :-1]], axis=1)\n",
    "        logit = model(images_shifted)\n",
    "        loss = cce(images, logit)\n",
    "        \n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    \n",
    "    return logit, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Main Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f076e89f67044adc89e82fc683bfbc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step : 1100 cross-entropy loss : 1.2902\n",
      "global step : 1200 cross-entropy loss : 1.6920943\n",
      "global step : 1300 cross-entropy loss : 1.5847172\n",
      "global step : 1400 cross-entropy loss : 1.4643587\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-675e6b9da2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for i, images in enumerate(train_dataset):\n",
    "        images = image_to_vector(images)\n",
    "        \n",
    "        logit, loss = train_step(model, optimizer, images)\n",
    "        model.global_step.assign_add(1)\n",
    "        global_step = model.global_step.numpy()\n",
    "        \n",
    "        if global_step % 100 == 0:\n",
    "            print('global step :', global_step, 'cross-entropy loss :', loss.numpy())\n",
    "        \n",
    "        if global_step % 1000 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            \n",
    "            print('Creating Images...')\n",
    "            images = model.inference(tf.zeros([10, width*height], dtype=tf.int64))\n",
    "            pred = vector_to_image(images, width, height)\n",
    "            \n",
    "            plt.figure(figsize=[18, 3])\n",
    "            for j in range(10):\n",
    "                plt.subplot(1, 10, j+1)\n",
    "                plt.imshow(pred[j], cmap='binary')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "            plt.show()     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with MNIST (or Fashion MNIST)\n",
    "\n",
    "* This code is available to tensorflow version 2.0\n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers) [`tf.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses)\n",
    "  \n",
    "![title](pics/lstm_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'lstm_mnist'\n",
    "train_dir = os.path.join('train', model_name, 'exp')\n",
    "dataset_name = 'mnist'\n",
    "assert dataset_name in ['mnist', 'fashion_mnist']\n",
    "\n",
    "max_epochs = 50\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "\n",
    "width, height = 14, 14\n",
    "TEST = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "if dataset_name == 'mnist':\n",
    "  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.mnist.load_data()\n",
    "else:\n",
    "## Load the MNIST dataset  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "train_images = tf.image.resize(train_images, size=[width, height])\n",
    "train_images = tf.cast(train_images[:, :, :, 0], tf.int64)\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "plt.figure(figsize=[18, 4])\n",
    "for i in range(3):\n",
    "    \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title('train image')\n",
    "    plt.imshow(train_images[i], cmap='binary')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.random.set_seed(117)\n",
    "# for train\n",
    "N = len(train_images)\n",
    "        \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size)\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, vocab_size=256, embed_dim=512, h_dim=512):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm_cell = layers.LSTMCell(units=h_dim)\n",
    "        self.logit_layer = layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # x : [batch, length]\n",
    "        \n",
    "        # [batch, length, embed_dim]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # LSTM states tuple\n",
    "        init_states = self.lstm_cell.get_initial_state(batch_size=x.shape[0], dtype=tf.float32)\n",
    "        states = init_states\n",
    "        output_list = []\n",
    "        for i in range(x.shape[1]):\n",
    "            # output : [batch, h_dim]\n",
    "            # states : (h : [batch, h_dim], c : [batch, h_dim])\n",
    "            \n",
    "            '''\n",
    "            빈칸 채우기 시작\n",
    "            '''\n",
    "            \n",
    "            output, states = self.lstm_cell(inputs=#빈칸#, states=states) # x의 i번째 픽셀 값 입력\n",
    "            output_list.append(#빈칸#) # output을 output_list에 append\n",
    "            \n",
    "            '''\n",
    "            빈칸 채우기 끝\n",
    "            '''\n",
    "        \n",
    "        outputs = tf.stack(output_list, axis=1)\n",
    "        logits = self.logit_layer(outputs)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "    def inference(self, batch_size):\n",
    "        x = tf.zeros([batch_size, 1], dtype=tf.int64)\n",
    "        \n",
    "        # [batch, 1, embed_dim]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # LSTM states tuple\n",
    "        init_states = self.lstm_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        states = init_states\n",
    "        samples = []\n",
    "        \n",
    "        for i in range(width*height):\n",
    "            # output : [batch, h_dim]\n",
    "            # states : (h : [batch, h_dim], c : [batch, h_dim])\n",
    "            '''\n",
    "            빈칸 채우기 시작\n",
    "            '''\n",
    "                \n",
    "            output, states = self.lstm_cell(inputs=#빈칸#, states=states) # x의 마지막 픽셀 값 입력\n",
    "            \n",
    "            # [batch, vocab_size]\n",
    "            logit = self.logit_layer(output)\n",
    "            # [batch, 1]\n",
    "            sample = tf.random.categorical(logit, num_samples=1)\n",
    "            samples.append(sample)\n",
    "            \n",
    "            # [batch, embed_dim]\n",
    "            sample_embed = self.embedding(sample)\n",
    "            # [batch, ..., embed_dim]\n",
    "            x = tf.concat(#빈칸#, axis=1) # x와 sample_embed를 concat\n",
    "                \n",
    "            '''\n",
    "            빈칸 채우기 끝\n",
    "            '''\n",
    "            \n",
    "        # [batch, width*height]\n",
    "        samples = tf.concat(samples, axis=1)\n",
    "        \n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D-image to 1D-vector, 1D-vector to 2D-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vector(images):\n",
    "    batch, height, width = images.shape\n",
    "    vector = tf.reshape(images, [batch, height*width])\n",
    "    return vector\n",
    "\n",
    "def vector_to_image(vectors, height, width):\n",
    "    batch, dim = vectors.shape\n",
    "    images = tf.reshape(vectors, [batch, height, width])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a unconditional image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = model.inference(batch_size=4)\n",
    "pred = vector_to_image(images, width, height)\n",
    "plt.imshow(pred[0], cmap='binary')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define a single train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, optimizer, images):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "           \n",
    "        images_shifted = tf.concat([tf.zeros([images.shape[0], 1], dtype=tf.int64), images[:, :-1]], axis=1)\n",
    "        logit = model(images_shifted)\n",
    "        loss = cce(images, logit)\n",
    "        \n",
    "    gradient = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_variables))\n",
    "    \n",
    "    return logit, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Main Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for i, images in enumerate(train_dataset):\n",
    "        images = image_to_vector(images)\n",
    "        \n",
    "        logit, loss = train_step(model, optimizer, images)\n",
    "        model.global_step.assign_add(1)\n",
    "        global_step = model.global_step.numpy()\n",
    "        \n",
    "        if global_step % 100 == 0:\n",
    "            print('global step :', global_step, 'cross-entropy loss :', loss.numpy())\n",
    "        \n",
    "        if global_step % 1000 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            \n",
    "            print('Creating Images...')\n",
    "            images = model.inference(batch_size=10)\n",
    "            pred = vector_to_image(images, width, height)\n",
    "            \n",
    "            plt.figure(figsize=[18, 3])\n",
    "            for j in range(10):\n",
    "                plt.subplot(1, 10, j+1)\n",
    "                plt.imshow(pred[j], cmap='binary')\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "            plt.show()     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
